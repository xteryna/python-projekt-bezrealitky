import json
import re
import requests
from bs4 import BeautifulSoup

def scrape_property_data(url):
    # St치hnout HTML obsah str치nky
    response = requests.get(url)
    if response.status_code != 200:
        print(f"Str치nka {url} nenalezena")
        return None
    
    # Anal칳za HTML pomoc칤 BeautifulSoup
    soup = BeautifulSoup(response.content, 'html.parser')
    
    # Nalezen칤 sekce s parametry nemovitosti
    params_section = soup.find('section', class_='box Section_section__gjwvr section mb-5 mb-lg-10')
    if not params_section:
        print(f"Sekce s parametry na str치nce {url} nenalezena")
        return None
    
    # Vyt치hnout jednotliv칠 parametry nemovitosti
    property_data = {}
    params_groups = params_section.find_all('div', class_='ParamsTable_paramsTableGroup__Flyfi')
    for group in params_groups:
        rows = group.find_all('tr')
        for row in rows:
            th = row.find('th')
            td = row.find('td')
            if th and td:
                property_data[th.text.strip()] = td.text.strip()
    
    # Nalezen칤 ceny nemovitosti
    price_div = soup.find('div', class_='justify-content-between align-items-baseline mb-lg-9 mb-6 row')
    if price_div:
        price_span = price_div.find('strong', class_='h4 fw-bold')
        if price_span:
            # Extrahovat textovou podobu ceny a odstranit mezery, symboly a ne쮂멳ouc칤 znaky odd캩lova캜콢 tis칤c콢
            price_text = price_span.text.strip().replace(' ', '').replace('K캜', '')
            # Odstranit ne쮂멳ouc칤 znaky odd캩lova캜콢 tis칤c콢
            price_text = re.sub(r'[^\d]', '', price_text)
            # P콏ev칠st textovou cenu na cel칠 캜칤slo (integer)
            property_data['Cena'] = int(price_text)
    
    # P콏ev칠st hodnotu Podla쮂 na integer
    if 'Podla쮂' in property_data:
        try:
            property_data['Podla쮂'] = int(property_data['Podla쮂'])
        except ValueError:
            pass
    
    # P콏ev칠st hodnotu U쬴tn치 plocha na integer
    if 'U쬴tn치 plocha' in property_data:
        try:
            # Extrahovat 캜칤selnou hodnotu z textu a odstranit mezery
            area_text = re.findall(r'\d+', property_data['U쬴tn치 plocha'])
            area_int = int(area_text[0]) if area_text else None
            property_data['U쬴tn치 plocha'] = area_int
        except ValueError:
            pass
    
    # Nalezen칤 informac칤 o bodech z치jmu v okol칤
    neighborhood_div = soup.find('div', class_='Neighborhood_neighborhoodTable__Ipy5I neighborhoodTable')
    if neighborhood_div:
        poi_items = neighborhood_div.find_all('div', class_='Poi_poiItem__7JgIz poiItem')
        poi_data = {}
        for item in poi_items:
            poi_type = item.find('span', class_='Poi_poiItemContentType__XukbX poiItemContentType')
            poi_name = item.find('strong', class_='poiItemContentName')
            poi_distance = item.find('div', class_='Poi_poiItemTimes__hse64 poiItemTimes')
            if poi_type and poi_name and poi_distance:
                distance_text = poi_distance.text.strip()
                distance_match = re.match(r'游뛌 (\d+) m \((\d+) min\)', distance_text)
                if distance_match:
                    meters = int(distance_match.group(1))
                    minutes = int(distance_match.group(2))
                    poi_type_text = poi_type.find('span').text.strip()  # Z칤skat text z vno콏en칠ho elementu span
                    poi_data[poi_type_text] = {
                        'Vzd치lenost': {'metry': meters, 'minuty': minutes}
                    }
        property_data['Body z치jmu v okol칤'] = poi_data
    
    # Extrahovat 칰daje z breadcrumb
    breadcrumb_div = soup.find('div', class_='Container_container--narrow__0pGYY container')
    if breadcrumb_div:
        breadcrumb_items = breadcrumb_div.find_all('li', class_='breadcrumb-item')
        num_items = len(breadcrumb_items)
        
        if num_items == 7:  # Praha
            property_data['Kraj'] = property_data['Okres'] = property_data['M캩sto'] = breadcrumb_items[4].text.strip()
            property_data['M캩stsk치 캜치st'] = breadcrumb_items[5].text.strip()
        elif num_items == 9:  # Velk치 m캩sta jako Brno
            property_data['Kraj'] = breadcrumb_items[4].text.strip()
            property_data['Okres'] = breadcrumb_items[5].text.strip()
            property_data['M캩sto'] = breadcrumb_items[6].text.strip()
            property_data['M캩stsk치 캜치st'] = breadcrumb_items[7].text.strip()
        elif num_items == 8:  # Men코칤 m캩sta jako Most
            property_data['Kraj'] = breadcrumb_items[4].text.strip()
            property_data['Okres'] = breadcrumb_items[5].text.strip()
            property_data['M캩sto'] = property_data['M캩stsk치 캜치st'] = breadcrumb_items[6].text.strip()
    
    # P콏idat URL str치nky do v칳sledn칳ch dat
    property_data['URL'] = url
    
    # Scrapovat text z elementu <div class="box mb-8">
    text_div = soup.find('div', class_='box mb-8')
    if text_div:
        paragraphs = text_div.find_all('p', class_='text-perex-lg') + text_div.find_all('p', class_='text-perex text-grey-dark')
        description = '\n'.join(paragraph.text.strip() for paragraph in paragraphs if paragraph.text.strip())
        property_data['Popis'] = description
    
    return property_data

# Na캜칤st seznam URL adres z JSON souboru
with open('apartments.json', 'r', encoding='utf-8') as file:
    urls = json.load(file)

# Proch치zen칤 seznamu URL adres
property_dict = {}
for i, url in enumerate(urls):
    print(f"Zpracov치v치 se: {url}")
    data = scrape_property_data(url)
    if data:
        property_dict[i] = data

# Ulo쬴t data do jednoho JSON souboru
with open('properties.json', 'w', encoding='utf-8') as json_file:
    json.dump(property_dict, json_file, ensure_ascii=False, indent=4)

print("Data ulo쬰na do properties.json")
